{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "File: train_emotion_classifier.py\n",
    "Author: Octavio Arriaga\n",
    "Email: arriaga.camargo@gmail.com\n",
    "Github: https://github.com/oarriaga\n",
    "Description: Train emotion classification model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from cnn import mini_XCEPTION\n",
    "from utils.datasets import DataManager\n",
    "from utils.datasets import split_data\n",
    "from utils.preprocessor import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0',\n",
       " '/job:localhost/replica:0/task:0/device:GPU:1']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend\n",
    "backend.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batch_size = 32\n",
    "num_epochs = 10000\n",
    "input_shape = (64, 64, 1)\n",
    "validation_split = .2\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 50\n",
    "base_path = '/data/emotion_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 62, 62, 8)    72          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 62, 62, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 62, 62, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 60, 60, 8)    576         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 60, 60, 8)    32          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 60, 60, 8)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 60, 60, 16)   200         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 60, 60, 16)   64          separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 60, 60, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 60, 60, 16)   400         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 60, 60, 16)   64          separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 30, 30, 16)   128         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 30, 30, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 30, 30, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 30, 30, 16)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 30, 30, 32)   656         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 30, 30, 32)   128         separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 30, 30, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 30, 30, 32)   1312        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 30, 30, 32)   128         separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 15, 15, 32)   512         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 15, 15, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 15, 15, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 15, 15, 32)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 15, 15, 64)   2336        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 15, 15, 64)   256         separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 15, 15, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 15, 15, 64)   4672        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 15, 15, 64)   256         separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 64)     2048        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 64)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 64)     256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 64)     0           max_pooling2d_3[0][0]            \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 8, 8, 128)    8768        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 128)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_8 (SeparableCo (None, 8, 8, 128)    17536       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 4, 4, 128)    8192        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 128)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 4, 128)    512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 4, 128)    0           max_pooling2d_4[0][0]            \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 4, 4, 7)      8071        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 7)            0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 7)            0           global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 58,423\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# data generator\n",
    "\n",
    "# model parameters/compilation\n",
    "model = mini_XCEPTION(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'fer2013'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = base_path + dataset_name + '_emotion_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                              patience=int(patience/4), verbose=1)\n",
    "trained_models_path = base_path + dataset_name + '_mini_XCEPTION'\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
    "                                                save_best_only=True)\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"/root/finalproject/tensorflow-for-poets-2/tf_files/Training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_WIDTH, IM_HEIGHT = 64, 64 #fixed size for InceptionV3\n",
    "NB_EPOCHS = 50\n",
    "BAT_SIZE = 32\n",
    "FC_SIZE = 1024\n",
    "NB_IV3_LAYERS_TO_FREEZE = 172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22970 images belonging to 7 classes.\n",
      "Found 5739 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_generator = ImageDataGenerator(\n",
    "                        preprocessing_function=preprocess_input,\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True,\n",
    "                        validation_split=0.2)\n",
    "    \n",
    "train_generator = data_generator.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "batch_size=BAT_SIZE,\n",
    "subset='training',\n",
    "color_mode=\"grayscale\")\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    train_data_dir, # same directory as training data\n",
    "    target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "    batch_size=BAT_SIZE,\n",
    "    subset='validation',\n",
    "color_mode=\"grayscale\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64, 1)\n",
      "(64, 64, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = train_generator.next()\n",
    "# for i in range(0,1):\n",
    "#     image = x[i]\n",
    "#     plt.imshow(image.transpose(2,1,0))\n",
    "#     plt.show()\n",
    "print(x.shape)\n",
    "image = x[2]\n",
    "print(image.shape)\n",
    "plt.imshow(image.reshape(IM_WIDTH, IM_HEIGHT))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "717/717 [==============================] - 47s 65ms/step - loss: 1.8064 - acc: 0.3106 - val_loss: 1.7123 - val_acc: 0.3453\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.71225, saving model to /data/emotion_models/fer2013_mini_XCEPTION.01-0.35.hdf5\n",
      "Epoch 2/50\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.5491 - acc: 0.4186 - val_loss: 1.6067 - val_acc: 0.3932\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.71225 to 1.60671, saving model to /data/emotion_models/fer2013_mini_XCEPTION.02-0.39.hdf5\n",
      "Epoch 3/50\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.4238 - acc: 0.4713 - val_loss: 1.5781 - val_acc: 0.4310\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.60671 to 1.57814, saving model to /data/emotion_models/fer2013_mini_XCEPTION.03-0.43.hdf5\n",
      "Epoch 4/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.3481 - acc: 0.4966 - val_loss: 1.4967 - val_acc: 0.4673\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.57814 to 1.49667, saving model to /data/emotion_models/fer2013_mini_XCEPTION.04-0.47.hdf5\n",
      "Epoch 5/50\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.2982 - acc: 0.5168 - val_loss: 1.3704 - val_acc: 0.4855\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.49667 to 1.37040, saving model to /data/emotion_models/fer2013_mini_XCEPTION.05-0.49.hdf5\n",
      "Epoch 6/50\n",
      "717/717 [==============================] - 43s 59ms/step - loss: 1.2597 - acc: 0.5280 - val_loss: 1.3118 - val_acc: 0.5162\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.37040 to 1.31179, saving model to /data/emotion_models/fer2013_mini_XCEPTION.06-0.52.hdf5\n",
      "Epoch 7/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.2297 - acc: 0.5395 - val_loss: 1.3198 - val_acc: 0.5166\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.31179\n",
      "Epoch 8/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.2105 - acc: 0.5481 - val_loss: 1.2846 - val_acc: 0.5176\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.31179 to 1.28457, saving model to /data/emotion_models/fer2013_mini_XCEPTION.08-0.52.hdf5\n",
      "Epoch 9/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.1907 - acc: 0.5562 - val_loss: 1.2186 - val_acc: 0.5470\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.28457 to 1.21865, saving model to /data/emotion_models/fer2013_mini_XCEPTION.09-0.55.hdf5\n",
      "Epoch 10/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.1748 - acc: 0.5635 - val_loss: 1.3477 - val_acc: 0.5083\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.21865\n",
      "Epoch 11/50\n",
      "717/717 [==============================] - 43s 59ms/step - loss: 1.1635 - acc: 0.5616 - val_loss: 1.2899 - val_acc: 0.5194\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.21865\n",
      "Epoch 12/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.1477 - acc: 0.5716 - val_loss: 1.2424 - val_acc: 0.5309\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.21865\n",
      "Epoch 13/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.1290 - acc: 0.5767 - val_loss: 1.2695 - val_acc: 0.5320\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.21865\n",
      "Epoch 14/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.1232 - acc: 0.5789 - val_loss: 1.3423 - val_acc: 0.5267\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.21865\n",
      "Epoch 15/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.1107 - acc: 0.5862 - val_loss: 1.2511 - val_acc: 0.5346\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.21865\n",
      "Epoch 16/50\n",
      "717/717 [==============================] - 43s 59ms/step - loss: 1.1073 - acc: 0.5870 - val_loss: 1.2846 - val_acc: 0.5262\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.21865\n",
      "Epoch 17/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.0893 - acc: 0.5949 - val_loss: 1.1901 - val_acc: 0.5653\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.21865 to 1.19007, saving model to /data/emotion_models/fer2013_mini_XCEPTION.17-0.57.hdf5\n",
      "Epoch 18/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.0847 - acc: 0.5927 - val_loss: 1.1819 - val_acc: 0.5612\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.19007 to 1.18187, saving model to /data/emotion_models/fer2013_mini_XCEPTION.18-0.56.hdf5\n",
      "Epoch 19/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.0745 - acc: 0.5958 - val_loss: 1.1873 - val_acc: 0.5686\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.18187\n",
      "Epoch 20/50\n",
      "717/717 [==============================] - 43s 59ms/step - loss: 1.0695 - acc: 0.5993 - val_loss: 1.1835 - val_acc: 0.5527\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.18187\n",
      "Epoch 21/50\n",
      "717/717 [==============================] - 43s 59ms/step - loss: 1.0604 - acc: 0.6042 - val_loss: 1.1249 - val_acc: 0.5849\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.18187 to 1.12495, saving model to /data/emotion_models/fer2013_mini_XCEPTION.21-0.58.hdf5\n",
      "Epoch 22/50\n",
      "717/717 [==============================] - 43s 59ms/step - loss: 1.0570 - acc: 0.6030 - val_loss: 1.2063 - val_acc: 0.5350\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.12495\n",
      "Epoch 23/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.0485 - acc: 0.6061 - val_loss: 1.1528 - val_acc: 0.5721\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.12495\n",
      "Epoch 24/50\n",
      "717/717 [==============================] - 43s 59ms/step - loss: 1.0430 - acc: 0.6109 - val_loss: 1.1677 - val_acc: 0.5749\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.12495\n",
      "Epoch 25/50\n",
      "717/717 [==============================] - 43s 59ms/step - loss: 1.0368 - acc: 0.6129 - val_loss: 1.1338 - val_acc: 0.5816\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.12495\n",
      "Epoch 26/50\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.0245 - acc: 0.6175 - val_loss: 1.1175 - val_acc: 0.5858\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.12495 to 1.11752, saving model to /data/emotion_models/fer2013_mini_XCEPTION.26-0.59.hdf5\n",
      "Epoch 27/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.0301 - acc: 0.6154 - val_loss: 1.1260 - val_acc: 0.5725\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.11752\n",
      "Epoch 28/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.0211 - acc: 0.6184 - val_loss: 1.1775 - val_acc: 0.5660\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.11752\n",
      "Epoch 29/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.0195 - acc: 0.6197 - val_loss: 1.1317 - val_acc: 0.5856\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.11752\n",
      "Epoch 30/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.0171 - acc: 0.6233 - val_loss: 1.2413 - val_acc: 0.5325\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.11752\n",
      "Epoch 31/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.0094 - acc: 0.6194 - val_loss: 1.1376 - val_acc: 0.5761\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.11752\n",
      "Epoch 32/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.0080 - acc: 0.6236 - val_loss: 1.1224 - val_acc: 0.5796\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.11752\n",
      "Epoch 33/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 1.0048 - acc: 0.6250 - val_loss: 1.1207 - val_acc: 0.5775\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.11752\n",
      "Epoch 34/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 0.9968 - acc: 0.6289 - val_loss: 1.1243 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.11752\n",
      "Epoch 35/50\n",
      "717/717 [==============================] - 43s 59ms/step - loss: 0.9944 - acc: 0.6310 - val_loss: 1.1268 - val_acc: 0.5765\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.11752\n",
      "Epoch 36/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 0.9907 - acc: 0.6320 - val_loss: 1.1179 - val_acc: 0.5840\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.11752\n",
      "Epoch 37/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 0.9854 - acc: 0.6368 - val_loss: 1.1121 - val_acc: 0.5851\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.11752 to 1.11209, saving model to /data/emotion_models/fer2013_mini_XCEPTION.37-0.59.hdf5\n",
      "Epoch 38/50\n",
      "717/717 [==============================] - 43s 59ms/step - loss: 0.9776 - acc: 0.6364 - val_loss: 1.1442 - val_acc: 0.5723\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.11209\n",
      "Epoch 39/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 0.9795 - acc: 0.6352 - val_loss: 1.1783 - val_acc: 0.5742\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.11209\n",
      "Epoch 40/50\n",
      "717/717 [==============================] - 43s 59ms/step - loss: 0.9700 - acc: 0.6402 - val_loss: 1.1475 - val_acc: 0.5856\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.11209\n",
      "Epoch 41/50\n",
      "717/717 [==============================] - 43s 59ms/step - loss: 0.9705 - acc: 0.6385 - val_loss: 1.1017 - val_acc: 0.5872\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.11209 to 1.10169, saving model to /data/emotion_models/fer2013_mini_XCEPTION.41-0.59.hdf5\n",
      "Epoch 42/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 0.9650 - acc: 0.6431 - val_loss: 1.1243 - val_acc: 0.5852\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.10169\n",
      "Epoch 43/50\n",
      "717/717 [==============================] - 43s 59ms/step - loss: 0.9646 - acc: 0.6410 - val_loss: 1.0800 - val_acc: 0.5891\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.10169 to 1.07996, saving model to /data/emotion_models/fer2013_mini_XCEPTION.43-0.59.hdf5\n",
      "Epoch 44/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 0.9577 - acc: 0.6441 - val_loss: 1.0981 - val_acc: 0.5952\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.07996\n",
      "Epoch 45/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 0.9595 - acc: 0.6433 - val_loss: 1.0896 - val_acc: 0.5949\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.07996\n",
      "Epoch 46/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 0.9562 - acc: 0.6431 - val_loss: 1.1069 - val_acc: 0.5880\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.07996\n",
      "Epoch 47/50\n",
      "717/717 [==============================] - 43s 59ms/step - loss: 0.9572 - acc: 0.6431 - val_loss: 1.1656 - val_acc: 0.5591\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.07996\n",
      "Epoch 48/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 0.9544 - acc: 0.6473 - val_loss: 1.0698 - val_acc: 0.6014\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.07996 to 1.06984, saving model to /data/emotion_models/fer2013_mini_XCEPTION.48-0.60.hdf5\n",
      "Epoch 49/50\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.9369 - acc: 0.6506 - val_loss: 1.1187 - val_acc: 0.6001\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.06984\n",
      "Epoch 50/50\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 0.9511 - acc: 0.6472 - val_loss: 1.0945 - val_acc: 0.5952\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.06984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f155326d908>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.fit_generator( \n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // BAT_SIZE,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // BAT_SIZE,\n",
    "    epochs=NB_EPOCHS, verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['fer2013']\n",
    "for dataset_name in datasets:\n",
    "    print('Training dataset:', dataset_name)\n",
    "\n",
    "    # callbacks\n",
    "    log_file_path = base_path + dataset_name + '_emotion_training.log'\n",
    "    csv_logger = CSVLogger(log_file_path, append=False)\n",
    "    early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "    reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                                  patience=int(patience/4), verbose=1)\n",
    "    trained_models_path = base_path + dataset_name + '_mini_XCEPTION'\n",
    "    model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "    model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
    "                                                    save_best_only=True)\n",
    "    callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "\n",
    "    # loading dataset\n",
    "    data_loader = DataManager(dataset_name, image_size=input_shape[:2])\n",
    "    faces, emotions = data_loader.get_data()\n",
    "    faces = preprocess_input(faces)\n",
    "    num_samples, num_classes = emotions.shape\n",
    "    train_data, val_data = split_data(faces, emotions, validation_split)\n",
    "    train_faces, train_emotions = train_data\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
