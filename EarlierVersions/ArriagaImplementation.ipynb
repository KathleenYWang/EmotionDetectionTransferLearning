{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFile: train_emotion_classifier.py\\nAuthor: Octavio Arriaga\\nEmail: arriaga.camargo@gmail.com\\nGithub: https://github.com/oarriaga\\nDescription: Train emotion classification model\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "File: train_emotion_classifier.py\n",
    "Author: Octavio Arriaga\n",
    "Email: arriaga.camargo@gmail.com\n",
    "Github: https://github.com/oarriaga\n",
    "Description: Train emotion classification model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install Pillow==2.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from cnn import mini_XCEPTION\n",
    "from utils.datasets import DataManager\n",
    "from utils.datasets import split_data\n",
    "from utils.preprocessor import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend\n",
    "backend.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batch_size = 32\n",
    "num_epochs = 10000\n",
    "input_shape = (64, 64, 1)\n",
    "validation_split = .2\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 50\n",
    "base_path = '/data/emotion_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 62, 62, 8)    72          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 62, 62, 8)    32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 62, 62, 8)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 60, 60, 8)    576         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 60, 60, 8)    32          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 60, 60, 8)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 60, 60, 16)   200         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 60, 60, 16)   64          separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 60, 60, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 60, 60, 16)   400         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 60, 60, 16)   64          separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 30, 30, 16)   128         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 30, 30, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 30, 30, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 30, 30, 16)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 30, 30, 32)   656         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 30, 30, 32)   128         separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 30, 30, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 30, 30, 32)   1312        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 30, 30, 32)   128         separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 15, 15, 32)   512         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 15, 15, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 15, 15, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 15, 15, 32)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 15, 15, 64)   2336        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 15, 15, 64)   256         separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 15, 15, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 15, 15, 64)   4672        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 15, 15, 64)   256         separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 64)     2048        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 64)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 64)     256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 64)     0           max_pooling2d_3[0][0]            \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 8, 8, 128)    8768        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 128)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_8 (SeparableCo (None, 8, 8, 128)    17536       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 4, 4, 128)    8192        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 128)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 4, 128)    512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 4, 128)    0           max_pooling2d_4[0][0]            \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 4, 4, 7)      8071        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 7)            0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 7)            0           global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 58,423\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# data generator\n",
    "\n",
    "# model parameters/compilation\n",
    "model = mini_XCEPTION(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'fer2013'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = base_path + dataset_name + '_emotion_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                              patience=int(patience/4), verbose=1)\n",
    "trained_models_path = base_path + dataset_name + '_mini_XCEPTION'\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
    "                                                save_best_only=True)\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_dir = \"/root/finalproject/tensorflow-for-poets-2/tf_files/Training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"/data/Training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_WIDTH, IM_HEIGHT = 64, 64 #fixed size for InceptionV3\n",
    "NB_EPOCHS = 10000\n",
    "BAT_SIZE = 32\n",
    "FC_SIZE = 1024\n",
    "NB_IV3_LAYERS_TO_FREEZE = 172\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22968 images belonging to 7 classes.\n",
      "Found 5740 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_generator = ImageDataGenerator(\n",
    "                        preprocessing_function=preprocess_input,\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True,\n",
    "                        validation_split=0.2)\n",
    "    \n",
    "train_generator = data_generator.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "batch_size=BAT_SIZE,\n",
    "subset='training',\n",
    "color_mode=\"grayscale\")\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    train_data_dir, # same directory as training data\n",
    "    target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "    batch_size=BAT_SIZE,\n",
    "    subset='validation',\n",
    "color_mode=\"grayscale\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64, 1)\n",
      "(64, 64, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = train_generator.next()\n",
    "# for i in range(0,1):\n",
    "#     image = x[i]\n",
    "#     plt.imshow(image.transpose(2,1,0))\n",
    "#     plt.show()\n",
    "print(x.shape)\n",
    "image = x[2]\n",
    "print(image.shape)\n",
    "plt.imshow(image.reshape(IM_WIDTH, IM_HEIGHT))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10000\n",
      "717/717 [==============================] - 54s 76ms/step - loss: 1.7965 - acc: 0.3192 - val_loss: 1.7187 - val_acc: 0.3521\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.71872, saving model to /data/emotion_models/fer2013_mini_XCEPTION.01-0.35.hdf5\n",
      "Epoch 2/10000\n",
      "717/717 [==============================] - 42s 58ms/step - loss: 1.5443 - acc: 0.4189 - val_loss: 1.5243 - val_acc: 0.4289\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.71872 to 1.52432, saving model to /data/emotion_models/fer2013_mini_XCEPTION.02-0.43.hdf5\n",
      "Epoch 3/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.4447 - acc: 0.4547 - val_loss: 1.7418 - val_acc: 0.3775\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.52432\n",
      "Epoch 4/10000\n",
      "717/717 [==============================] - 43s 59ms/step - loss: 1.3654 - acc: 0.4875 - val_loss: 1.4513 - val_acc: 0.4615\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.52432 to 1.45133, saving model to /data/emotion_models/fer2013_mini_XCEPTION.04-0.46.hdf5\n",
      "Epoch 5/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.3159 - acc: 0.5053 - val_loss: 1.3732 - val_acc: 0.4772\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.45133 to 1.37322, saving model to /data/emotion_models/fer2013_mini_XCEPTION.05-0.48.hdf5\n",
      "Epoch 6/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.2834 - acc: 0.5202 - val_loss: 1.3061 - val_acc: 0.5109\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.37322 to 1.30615, saving model to /data/emotion_models/fer2013_mini_XCEPTION.06-0.51.hdf5\n",
      "Epoch 7/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.2569 - acc: 0.5250 - val_loss: 1.3306 - val_acc: 0.5145\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.30615\n",
      "Epoch 8/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.1795 - acc: 0.5598 - val_loss: 1.2131 - val_acc: 0.5343\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.25236 to 1.21308, saving model to /data/emotion_models/fer2013_mini_XCEPTION.11-0.53.hdf5\n",
      "Epoch 12/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.1543 - acc: 0.5648 - val_loss: 1.2751 - val_acc: 0.5259\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.21308\n",
      "Epoch 13/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.1477 - acc: 0.5712 - val_loss: 1.2531 - val_acc: 0.5340\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.21308\n",
      "Epoch 14/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.1342 - acc: 0.5767 - val_loss: 1.2014 - val_acc: 0.5559\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.21308 to 1.20138, saving model to /data/emotion_models/fer2013_mini_XCEPTION.14-0.56.hdf5\n",
      "Epoch 15/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.1278 - acc: 0.5802 - val_loss: 1.2239 - val_acc: 0.5508\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.20138\n",
      "Epoch 16/10000\n",
      "717/717 [==============================] - 42s 58ms/step - loss: 1.1117 - acc: 0.5855 - val_loss: 1.1779 - val_acc: 0.5489\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.20138 to 1.17787, saving model to /data/emotion_models/fer2013_mini_XCEPTION.16-0.55.hdf5\n",
      "Epoch 17/10000\n",
      "367/717 [==============>...............] - ETA: 17s - loss: 1.0924 - acc: 0.5862"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717/717 [==============================] - 42s 59ms/step - loss: 1.0920 - acc: 0.5907 - val_loss: 1.2494 - val_acc: 0.5247\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.17787\n",
      "Epoch 19/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.0864 - acc: 0.5936 - val_loss: 1.1928 - val_acc: 0.5478\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.17787\n",
      "Epoch 20/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.0737 - acc: 0.6013 - val_loss: 1.2082 - val_acc: 0.5538\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.17787\n",
      "Epoch 21/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.0716 - acc: 0.6007 - val_loss: 1.2373 - val_acc: 0.5420\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.17787\n",
      "Epoch 22/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.0637 - acc: 0.6048 - val_loss: 1.1292 - val_acc: 0.5718\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.17787 to 1.12920, saving model to /data/emotion_models/fer2013_mini_XCEPTION.22-0.57.hdf5\n",
      "Epoch 23/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.0579 - acc: 0.6057 - val_loss: 1.1696 - val_acc: 0.5660\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.12920\n",
      "Epoch 24/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.0500 - acc: 0.6085 - val_loss: 1.1896 - val_acc: 0.5548\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.12920\n",
      "Epoch 25/10000\n",
      "101/717 [===>..........................] - ETA: 30s - loss: 1.0348 - acc: 0.6175"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717/717 [==============================] - 43s 60ms/step - loss: 1.0224 - acc: 0.6180 - val_loss: 1.1212 - val_acc: 0.5820\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.11129\n",
      "Epoch 31/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.0092 - acc: 0.6244 - val_loss: 1.1856 - val_acc: 0.5629\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.11129\n",
      "Epoch 32/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.0104 - acc: 0.6205 - val_loss: 1.1296 - val_acc: 0.5752\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.11129\n",
      "Epoch 33/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 1.0060 - acc: 0.6300 - val_loss: 1.1827 - val_acc: 0.5646\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.11129\n",
      "Epoch 34/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.9973 - acc: 0.6286 - val_loss: 1.1278 - val_acc: 0.5906\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.11129\n",
      "Epoch 35/10000\n",
      "549/717 [=====================>........] - ETA: 8s - loss: 0.9836 - acc: 0.6330"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717/717 [==============================] - 42s 59ms/step - loss: 0.9710 - acc: 0.6404 - val_loss: 1.1096 - val_acc: 0.5834\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.10204\n",
      "Epoch 42/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.9650 - acc: 0.6432 - val_loss: 1.1359 - val_acc: 0.5808\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.10204\n",
      "Epoch 43/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.9646 - acc: 0.6429 - val_loss: 1.1128 - val_acc: 0.5892\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.10204\n",
      "Epoch 44/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.9598 - acc: 0.6412 - val_loss: 1.1192 - val_acc: 0.5774\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.10204\n",
      "Epoch 45/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.9566 - acc: 0.6450 - val_loss: 1.0800 - val_acc: 0.6025\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.10204 to 1.07997, saving model to /data/emotion_models/fer2013_mini_XCEPTION.45-0.60.hdf5\n",
      "Epoch 46/10000\n",
      "450/717 [=================>............] - ETA: 13s - loss: 0.9484 - acc: 0.6493"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717/717 [==============================] - 42s 59ms/step - loss: 0.9358 - acc: 0.6519 - val_loss: 1.1129 - val_acc: 0.5913\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.07046\n",
      "Epoch 53/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.9351 - acc: 0.6513 - val_loss: 1.1263 - val_acc: 0.5860\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.07046\n",
      "Epoch 54/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.9380 - acc: 0.6522 - val_loss: 1.0585 - val_acc: 0.6063\n",
      "\n",
      "Epoch 00054: val_loss improved from 1.07046 to 1.05846, saving model to /data/emotion_models/fer2013_mini_XCEPTION.54-0.61.hdf5\n",
      "Epoch 55/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.9310 - acc: 0.6548 - val_loss: 1.1459 - val_acc: 0.5741\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.05846\n",
      "Epoch 56/10000\n",
      "717/717 [==============================] - 43s 59ms/step - loss: 0.9362 - acc: 0.6561 - val_loss: 1.0773 - val_acc: 0.6055\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.05846\n",
      "Epoch 57/10000\n",
      "529/717 [=====================>........] - ETA: 9s - loss: 0.9226 - acc: 0.656"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717/717 [==============================] - 42s 59ms/step - loss: 0.9201 - acc: 0.6611 - val_loss: 1.0766 - val_acc: 0.6044\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.05846\n",
      "Epoch 59/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.9146 - acc: 0.6612 - val_loss: 1.1027 - val_acc: 0.5823\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.05846\n",
      "Epoch 60/10000\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 0.9175 - acc: 0.6598 - val_loss: 1.1094 - val_acc: 0.5806\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.05846\n",
      "Epoch 61/10000\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 0.9111 - acc: 0.6623 - val_loss: 1.0826 - val_acc: 0.5979\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.05846\n",
      "Epoch 62/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.9196 - acc: 0.6581 - val_loss: 1.0873 - val_acc: 0.6065\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.05846\n",
      "Epoch 63/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.9091 - acc: 0.6608 - val_loss: 1.1254 - val_acc: 0.5957\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.05846\n",
      "Epoch 64/10000\n",
      "717/717 [==============================] - 43s 59ms/step - loss: 0.9020 - acc: 0.6642 - val_loss: 1.1348 - val_acc: 0.5909\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.05846\n",
      "Epoch 65/10000\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 0.9091 - acc: 0.6651 - val_loss: 1.0819 - val_acc: 0.5951\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.05846\n",
      "Epoch 66/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.9004 - acc: 0.6645 - val_loss: 1.1070 - val_acc: 0.6028\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.05846\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 67/10000\n",
      "717/717 [==============================] - 43s 59ms/step - loss: 0.8608 - acc: 0.6816 - val_loss: 1.0311 - val_acc: 0.6202\n",
      "\n",
      "Epoch 00067: val_loss improved from 1.05846 to 1.03114, saving model to /data/emotion_models/fer2013_mini_XCEPTION.67-0.62.hdf5\n",
      "Epoch 68/10000\n",
      "717/717 [==============================] - 43s 60ms/step - loss: 0.8342 - acc: 0.6938 - val_loss: 1.0294 - val_acc: 0.6142\n",
      "\n",
      "Epoch 00068: val_loss improved from 1.03114 to 1.02941, saving model to /data/emotion_models/fer2013_mini_XCEPTION.68-0.61.hdf5\n",
      "Epoch 69/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.8315 - acc: 0.6963 - val_loss: 1.0110 - val_acc: 0.6275\n",
      "\n",
      "Epoch 00069: val_loss improved from 1.02941 to 1.01100, saving model to /data/emotion_models/fer2013_mini_XCEPTION.69-0.63.hdf5\n",
      "Epoch 70/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.8204 - acc: 0.7010 - val_loss: 1.0347 - val_acc: 0.6111\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.01100\n",
      "Epoch 71/10000\n",
      "717/717 [==============================] - 43s 59ms/step - loss: 0.8206 - acc: 0.6997 - val_loss: 1.0184 - val_acc: 0.6205\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.01100\n",
      "Epoch 72/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.8161 - acc: 0.6997 - val_loss: 1.0358 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.01100\n",
      "Epoch 73/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.8180 - acc: 0.6996 - val_loss: 1.0329 - val_acc: 0.6186\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.01100\n",
      "Epoch 74/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.8135 - acc: 0.6997 - val_loss: 1.0382 - val_acc: 0.6097\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.01100\n",
      "Epoch 75/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.8091 - acc: 0.7004 - val_loss: 1.0254 - val_acc: 0.6200\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.01100\n",
      "Epoch 76/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.8098 - acc: 0.7008 - val_loss: 1.0270 - val_acc: 0.6205\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.01100\n",
      "Epoch 77/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.8010 - acc: 0.7074 - val_loss: 1.0478 - val_acc: 0.6151\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.01100\n",
      "Epoch 78/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.8063 - acc: 0.7042 - val_loss: 1.0501 - val_acc: 0.6114\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.01100\n",
      "Epoch 79/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.7992 - acc: 0.7061 - val_loss: 1.0255 - val_acc: 0.6184\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.01100\n",
      "Epoch 80/10000\n",
      "717/717 [==============================] - 42s 59ms/step - loss: 0.8089 - acc: 0.7007 - val_loss: 1.0427 - val_acc: 0.6141\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.01100\n",
      "Epoch 81/10000\n",
      "715/717 [============================>.] - ETA: 0s - loss: 0.8064 - acc: 0.7028"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time. time()\n",
    "\n",
    "\n",
    "model.fit_generator( \n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // BAT_SIZE,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // BAT_SIZE,\n",
    "    epochs=NB_EPOCHS, verbose=1, callbacks=callbacks)\n",
    "\n",
    "end = time. time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['fer2013']\n",
    "for dataset_name in datasets:\n",
    "    print('Training dataset:', dataset_name)\n",
    "\n",
    "    # callbacks\n",
    "    log_file_path = base_path + dataset_name + '_emotion_training.log'\n",
    "    csv_logger = CSVLogger(log_file_path, append=False)\n",
    "    early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "    reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                                  patience=int(patience/4), verbose=1)\n",
    "    trained_models_path = base_path + dataset_name + '_mini_XCEPTION'\n",
    "    model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "    model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
    "                                                    save_best_only=True)\n",
    "    callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "\n",
    "    # loading dataset\n",
    "    data_loader = DataManager(dataset_name, image_size=input_shape[:2])\n",
    "    faces, emotions = data_loader.get_data()\n",
    "    faces = preprocess_input(faces)\n",
    "    num_samples, num_classes = emotions.shape\n",
    "    train_data, val_data = split_data(faces, emotions, validation_split)\n",
    "    train_faces, train_emotions = train_data\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
