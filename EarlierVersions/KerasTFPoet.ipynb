{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/data/tensorflow-for-poets-2/tf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import argparse\n",
    "from keras import __version__\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from PIL import Image,ImageDraw,ImageFont\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0',\n",
       " '/job:localhost/replica:0/task:0/device:GPU:1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend\n",
    "backend.tensorflow_backend._get_available_gpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_WIDTH, IM_HEIGHT = 299, 299 #fixed size for InceptionV3\n",
    "NB_EPOCHS = 3\n",
    "BAT_SIZE = 32\n",
    "FC_SIZE = 1024\n",
    "NB_IV3_LAYERS_TO_FREEZE = 172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"/root/finalproject/tensorflow-for-poets-2/tf_files/Training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_datagen = ImageDataGenerator(\n",
    "# preprocessing_function=preprocess_input,\n",
    "# rotation_range=30,\n",
    "# width_shift_range=0.2,\n",
    "# height_shift_range=0.2,\n",
    "# shear_range=0.2,\n",
    "# zoom_range=0.2,\n",
    "# horizontal_flip=True\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28707 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# train_generator = train_datagen.flow_from_directory(\n",
    "# train_data_dir,\n",
    "# target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "# batch_size = BAT_SIZE, \n",
    "# class_mode = \"categorical\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nb_files(directory):\n",
    "    \"\"\"Get number of files by searching directory recursively\"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        return 0\n",
    "    cnt = 0\n",
    "    for r, dirs, files in os.walk(directory):\n",
    "        for dr in dirs:\n",
    "            cnt += len(glob.glob(os.path.join(r, dr + \"/*\")))\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_to_transfer_learn(model, base_model):\n",
    "    \"\"\"Freeze all layers and compile the model\"\"\"\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_last_layer(base_model, nb_classes):\n",
    "    \"\"\"Add last layer to the convnet\n",
    "    Args:\n",
    "    base_model: keras model excluding top\n",
    "    nb_classes: # of classes\n",
    "    Returns:\n",
    "    new keras model with last layer\n",
    "    \"\"\"\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(FC_SIZE, activation='relu')(x) #new FC layer, random init\n",
    "    predictions = Dense(nb_classes, activation='softmax')(x) #new softmax layer\n",
    "    model = Model(input=base_model.input, output=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_to_finetune(model):\n",
    "    \"\"\"Freeze the bottom NB_IV3_LAYERS and retrain the remaining top layers.\n",
    "    note: NB_IV3_LAYERS corresponds to the top 2 inception blocks in the inceptionv3 arch\n",
    "    Args:\n",
    "    model: keras model\n",
    "    \"\"\"\n",
    "    for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
    "        layer.trainable = True\n",
    "    model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dir, nb_epoch,batch_size, out_dir):\n",
    "    \"\"\"Use transfer learning and fine-tuning to train a network on a new dataset\"\"\"\n",
    "    nb_train_samples = get_nb_files(train_dir)\n",
    "    nb_classes = 7\n",
    "#     nb_val_samples = get_nb_files(args.val_dir)\n",
    "    nb_epoch = int(nb_epoch)\n",
    "    batch_size = int(batch_size)\n",
    "    # data prep\n",
    "    train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    "    )\n",
    "    \n",
    "#     test_datagen = ImageDataGenerator(\n",
    "#     preprocessing_function=preprocess_input,\n",
    "#     rotation_range=30,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True\n",
    "#     )\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "    batch_size=batch_size,\n",
    "    )\n",
    "#     validation_generator = test_datagen.flow_from_directory(\n",
    "#     args.val_dir,\n",
    "#     target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "#     batch_size=batch_size,\n",
    "#     )\n",
    "    # setup model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False) #include_top=False excludes final FC layer\n",
    "    model = add_new_last_layer(base_model, nb_classes)\n",
    "    # transfer learning\n",
    "    setup_to_transfer_learn(model, base_model)\n",
    "    \n",
    "        # Save the model according to the conditions  \n",
    "    checkpoint = ModelCheckpoint(out_dir, monitor='acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    early = EarlyStopping(monitor='acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "    \n",
    "    \n",
    "    history_tl = model.fit_generator(\n",
    "    train_generator,\n",
    "    nb_epoch=nb_epoch,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "#     validation_data=validation_generator,\n",
    "#     nb_val_samples=nb_val_samples,\n",
    "    class_weight='auto',\n",
    "    callbacks = [checkpoint, early])\n",
    "    \n",
    "    # fine-tuning\n",
    "    setup_to_finetune(model)\n",
    "    history_ft = model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    nb_epoch=nb_epoch,\n",
    "#     validation_data=validation_generator,\n",
    "#     nb_val_samples=nb_val_samples,\n",
    "    class_weight='auto',\n",
    "    callbacks = [checkpoint, early])\n",
    "    \n",
    "    model.save(out_dir)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_WIDTH, IM_HEIGHT = 299, 299 #fixed size for InceptionV3\n",
    "NB_EPOCHS = 50\n",
    "BAT_SIZE = 10\n",
    "FC_SIZE = 1024\n",
    "NB_IV3_LAYERS_TO_FREEZE = 172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28707 images belonging to 7 classes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:58: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:58: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=2870, callbacks=[<keras.ca..., epochs=50, class_weight=\"auto\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2870/2870 [==============================] - 614s 214ms/step - loss: 2.3123 - acc: 0.2679\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.26791, saving model to /data/inception\n",
      "Epoch 2/50\n",
      "2870/2870 [==============================] - 619s 216ms/step - loss: 1.7207 - acc: 0.3037\n",
      "\n",
      "Epoch 00002: acc improved from 0.26791 to 0.30373, saving model to /data/inception\n",
      "Epoch 3/50\n",
      "2870/2870 [==============================] - 612s 213ms/step - loss: 1.7062 - acc: 0.3137\n",
      "\n",
      "Epoch 00003: acc improved from 0.30373 to 0.31369, saving model to /data/inception\n",
      "Epoch 4/50\n",
      "2870/2870 [==============================] - 610s 213ms/step - loss: 1.6956 - acc: 0.3203\n",
      "\n",
      "Epoch 00004: acc improved from 0.31369 to 0.32028, saving model to /data/inception\n",
      "Epoch 5/50\n",
      "2870/2870 [==============================] - 611s 213ms/step - loss: 1.6912 - acc: 0.3244\n",
      "\n",
      "Epoch 00005: acc improved from 0.32028 to 0.32446, saving model to /data/inception\n",
      "Epoch 6/50\n",
      "2870/2870 [==============================] - 611s 213ms/step - loss: 1.6883 - acc: 0.3267\n",
      "\n",
      "Epoch 00006: acc improved from 0.32446 to 0.32665, saving model to /data/inception\n",
      "Epoch 7/50\n",
      "2870/2870 [==============================] - 611s 213ms/step - loss: 1.6904 - acc: 0.3280\n",
      "\n",
      "Epoch 00007: acc improved from 0.32665 to 0.32801, saving model to /data/inception\n",
      "Epoch 8/50\n",
      "2870/2870 [==============================] - 612s 213ms/step - loss: 1.6853 - acc: 0.3286\n",
      "\n",
      "Epoch 00008: acc improved from 0.32801 to 0.32854, saving model to /data/inception\n",
      "Epoch 9/50\n",
      "2870/2870 [==============================] - 612s 213ms/step - loss: 1.6870 - acc: 0.3289\n",
      "\n",
      "Epoch 00009: acc improved from 0.32854 to 0.32895, saving model to /data/inception\n",
      "Epoch 10/50\n",
      "2870/2870 [==============================] - 612s 213ms/step - loss: 1.6815 - acc: 0.3312\n",
      "\n",
      "Epoch 00010: acc improved from 0.32895 to 0.33118, saving model to /data/inception\n",
      "Epoch 11/50\n",
      "2870/2870 [==============================] - 612s 213ms/step - loss: 1.6822 - acc: 0.3331\n",
      "\n",
      "Epoch 00011: acc improved from 0.33118 to 0.33310, saving model to /data/inception\n",
      "Epoch 12/50\n",
      "2870/2870 [==============================] - 612s 213ms/step - loss: 1.6843 - acc: 0.3288\n",
      "\n",
      "Epoch 00012: acc did not improve from 0.33310\n",
      "Epoch 13/50\n",
      "2870/2870 [==============================] - 610s 213ms/step - loss: 1.6784 - acc: 0.3321\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.33310\n",
      "Epoch 14/50\n",
      "2870/2870 [==============================] - 603s 210ms/step - loss: 1.6787 - acc: 0.3331\n",
      "\n",
      "Epoch 00014: acc improved from 0.33310 to 0.33310, saving model to /data/inception\n",
      "Epoch 15/50\n",
      "2870/2870 [==============================] - 608s 212ms/step - loss: 1.6796 - acc: 0.3344\n",
      "\n",
      "Epoch 00015: acc improved from 0.33310 to 0.33439, saving model to /data/inception\n",
      "Epoch 16/50\n",
      "2870/2870 [==============================] - 608s 212ms/step - loss: 1.6753 - acc: 0.3361\n",
      "\n",
      "Epoch 00016: acc improved from 0.33439 to 0.33606, saving model to /data/inception\n",
      "Epoch 17/50\n",
      "2870/2870 [==============================] - 608s 212ms/step - loss: 1.6800 - acc: 0.3362\n",
      "\n",
      "Epoch 00017: acc improved from 0.33606 to 0.33627, saving model to /data/inception\n",
      "Epoch 18/50\n",
      "2870/2870 [==============================] - 607s 211ms/step - loss: 1.6765 - acc: 0.3346\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.33627\n",
      "Epoch 19/50\n",
      "2382/2870 [=======================>......] - ETA: 1:43 - loss: 1.6743 - acc: 0.3359"
     ]
    }
   ],
   "source": [
    "train(train_dir = train_data_dir, nb_epoch= NB_EPOCHS, batch_size=BAT_SIZE, out_dir = \"/data/inception\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_train(train_dir, nb_epoch,batch_size, out_dir):\n",
    "    \"\"\"Use transfer learning and fine-tuning to train a network on a new dataset\"\"\"\n",
    "    nb_train_samples = get_nb_files(train_dir)\n",
    "    nb_classes = 7\n",
    "#     nb_val_samples = get_nb_files(args.val_dir)\n",
    "    nb_epoch = int(nb_epoch)\n",
    "    batch_size = int(batch_size)\n",
    "    # data prep\n",
    "    train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    "    )\n",
    "    \n",
    "#     test_datagen = ImageDataGenerator(\n",
    "#     preprocessing_function=preprocess_input,\n",
    "#     rotation_range=30,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True\n",
    "#     )\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "    batch_size=batch_size,\n",
    "    )\n",
    "#     validation_generator = test_datagen.flow_from_directory(\n",
    "#     args.val_dir,\n",
    "#     target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "#     batch_size=batch_size,\n",
    "#     )\n",
    "    # setup model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False) #include_top=False excludes final FC layer\n",
    "    model = add_new_last_layer(base_model, nb_classes)\n",
    "    # transfer learning\n",
    "    setup_to_transfer_learn(model, base_model)\n",
    "    \n",
    "        # Save the model according to the conditions  \n",
    "    checkpoint = ModelCheckpoint(out_dir, monitor='acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    early = EarlyStopping(monitor='acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "    cont_model = load_model(\"/data/inception\")\n",
    "    \n",
    "    history_tl = cont_model.fit_generator(\n",
    "    train_generator,\n",
    "    nb_epoch=nb_epoch,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "#     validation_data=validation_generator,\n",
    "#     nb_val_samples=nb_val_samples,\n",
    "    class_weight='auto',\n",
    "    callbacks = [checkpoint, early])\n",
    "    \n",
    "    # fine-tuning\n",
    "    setup_to_finetune(cont_model)\n",
    "    history_ft = cont_model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    nb_epoch=nb_epoch,\n",
    "#     validation_data=validation_generator,\n",
    "#     nb_val_samples=nb_val_samples,\n",
    "    class_weight='auto',\n",
    "    callbacks = [checkpoint, early])\n",
    "    \n",
    "    model.save(out_dir)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28707 images belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:58: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:58: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., class_weight=\"auto\", steps_per_epoch=2870, callbacks=[<keras.ca..., epochs=15)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2870/2870 [==============================] - 609s 212ms/step - loss: 1.6790 - acc: 0.3383\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.33826, saving model to /data/inception\n",
      "Epoch 2/15\n",
      "2870/2870 [==============================] - 604s 211ms/step - loss: 1.6731 - acc: 0.3368\n",
      "\n",
      "Epoch 00002: acc did not improve from 0.33826\n",
      "Epoch 3/15\n",
      "2870/2870 [==============================] - 606s 211ms/step - loss: 1.6762 - acc: 0.3369\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.33826\n",
      "Epoch 4/15\n",
      "2870/2870 [==============================] - 614s 214ms/step - loss: 1.6773 - acc: 0.3380\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.33826\n",
      "Epoch 5/15\n",
      "2870/2870 [==============================] - 616s 215ms/step - loss: 1.6755 - acc: 0.3398\n",
      "\n",
      "Epoch 00005: acc improved from 0.33826 to 0.33976, saving model to /data/inception\n",
      "Epoch 6/15\n",
      "2870/2870 [==============================] - 603s 210ms/step - loss: 1.6828 - acc: 0.3392\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.33976\n",
      "Epoch 7/15\n",
      "2870/2870 [==============================] - 606s 211ms/step - loss: 1.6828 - acc: 0.3398\n",
      "\n",
      "Epoch 00007: acc improved from 0.33976 to 0.33976, saving model to /data/inception\n",
      "Epoch 8/15\n",
      "2870/2870 [==============================] - 610s 213ms/step - loss: 1.6795 - acc: 0.3358\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.33976\n",
      "Epoch 9/15\n",
      "2870/2870 [==============================] - 605s 211ms/step - loss: 1.6833 - acc: 0.3364\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.33976\n",
      "Epoch 10/15\n",
      "2870/2870 [==============================] - 610s 212ms/step - loss: 1.6873 - acc: 0.3371\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.33976\n",
      "Epoch 11/15\n",
      "2870/2870 [==============================] - 605s 211ms/step - loss: 1.6876 - acc: 0.3346\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.33976\n",
      "Epoch 12/15\n",
      "2870/2870 [==============================] - 614s 214ms/step - loss: 1.6815 - acc: 0.3420\n",
      "\n",
      "Epoch 00012: acc improved from 0.33976 to 0.34202, saving model to /data/inception\n",
      "Epoch 13/15\n",
      "2344/2870 [=======================>......] - ETA: 1:51 - loss: 1.6920 - acc: 0.3320"
     ]
    }
   ],
   "source": [
    "continue_train(train_dir = train_data_dir, nb_epoch= 15, batch_size=BAT_SIZE, out_dir = \"/data/inception\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_finetune(train_dir, nb_epoch,batch_size, out_dir):\n",
    "    \"\"\"Use transfer learning and fine-tuning to train a network on a new dataset\"\"\"\n",
    "    nb_train_samples = get_nb_files(train_dir)\n",
    "    nb_classes = 7\n",
    "#     nb_val_samples = get_nb_files(args.val_dir)\n",
    "    nb_epoch = int(nb_epoch)\n",
    "    batch_size = int(batch_size)\n",
    "    # data prep\n",
    "    train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    "    )\n",
    "    \n",
    "#     test_datagen = ImageDataGenerator(\n",
    "#     preprocessing_function=preprocess_input,\n",
    "#     rotation_range=30,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True\n",
    "#     )\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "    batch_size=batch_size,\n",
    "    )\n",
    "#     validation_generator = test_datagen.flow_from_directory(\n",
    "#     args.val_dir,\n",
    "#     target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "#     batch_size=batch_size,\n",
    "#     )\n",
    "    # setup model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False) #include_top=False excludes final FC layer\n",
    "    model = add_new_last_layer(base_model, nb_classes)\n",
    "    # transfer learning\n",
    "    setup_to_transfer_learn(model, base_model)\n",
    "    \n",
    "        # Save the model according to the conditions  \n",
    "    checkpoint = ModelCheckpoint(out_dir, monitor='acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    early = EarlyStopping(monitor='acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "    cont_model = load_model(\"/data/inception\")\n",
    "    \n",
    "    # fine-tuning\n",
    "    setup_to_finetune(cont_model)\n",
    "    history_ft = cont_model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    nb_epoch=nb_epoch,\n",
    "#     validation_data=validation_generator,\n",
    "#     nb_val_samples=nb_val_samples,\n",
    "    class_weight='auto',\n",
    "    callbacks = [checkpoint, early])\n",
    "    \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28707 images belonging to 7 classes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:60: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:60: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=2870, class_weight=\"auto\", callbacks=[<keras.ca..., epochs=15)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2870/2870 [==============================] - 619s 216ms/step - loss: 1.6005 - acc: 0.3783\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.37833, saving model to /data/inception\n",
      "Epoch 2/15\n",
      "2870/2870 [==============================] - 608s 212ms/step - loss: 1.4970 - acc: 0.4271\n",
      "\n",
      "Epoch 00002: acc improved from 0.37833 to 0.42708, saving model to /data/inception\n",
      "Epoch 3/15\n",
      "2870/2870 [==============================] - 608s 212ms/step - loss: 1.4402 - acc: 0.4543\n",
      "\n",
      "Epoch 00003: acc improved from 0.42708 to 0.45433, saving model to /data/inception\n",
      "Epoch 4/15\n",
      "2870/2870 [==============================] - 609s 212ms/step - loss: 1.3984 - acc: 0.4664\n",
      "\n",
      "Epoch 00004: acc improved from 0.45433 to 0.46639, saving model to /data/inception\n",
      "Epoch 5/15\n",
      "2870/2870 [==============================] - 609s 212ms/step - loss: 1.3642 - acc: 0.4834\n",
      "\n",
      "Epoch 00005: acc improved from 0.46639 to 0.48336, saving model to /data/inception\n",
      "Epoch 6/15\n",
      "2870/2870 [==============================] - 609s 212ms/step - loss: 1.3313 - acc: 0.4924\n",
      "\n",
      "Epoch 00006: acc improved from 0.48336 to 0.49246, saving model to /data/inception\n",
      "Epoch 7/15\n",
      "2870/2870 [==============================] - 610s 213ms/step - loss: 1.3119 - acc: 0.5018\n",
      "\n",
      "Epoch 00007: acc improved from 0.49246 to 0.50176, saving model to /data/inception\n",
      "Epoch 8/15\n",
      "2870/2870 [==============================] - 612s 213ms/step - loss: 1.2789 - acc: 0.5120\n",
      "\n",
      "Epoch 00008: acc improved from 0.50176 to 0.51200, saving model to /data/inception\n",
      "Epoch 9/15\n",
      "2870/2870 [==============================] - 611s 213ms/step - loss: 1.2575 - acc: 0.5220\n",
      "\n",
      "Epoch 00009: acc improved from 0.51200 to 0.52204, saving model to /data/inception\n",
      "Epoch 10/15\n",
      "2870/2870 [==============================] - 608s 212ms/step - loss: 1.2480 - acc: 0.5273\n",
      "\n",
      "Epoch 00010: acc improved from 0.52204 to 0.52734, saving model to /data/inception\n",
      "Epoch 11/15\n",
      "2870/2870 [==============================] - 609s 212ms/step - loss: 1.2219 - acc: 0.5379\n",
      "\n",
      "Epoch 00011: acc improved from 0.52734 to 0.53790, saving model to /data/inception\n",
      "Epoch 12/15\n",
      "2870/2870 [==============================] - 607s 212ms/step - loss: 1.2129 - acc: 0.5441\n",
      "\n",
      "Epoch 00012: acc improved from 0.53790 to 0.54410, saving model to /data/inception\n",
      "Epoch 13/15\n",
      "2870/2870 [==============================] - 608s 212ms/step - loss: 1.2000 - acc: 0.5481\n",
      "\n",
      "Epoch 00013: acc improved from 0.54410 to 0.54811, saving model to /data/inception\n",
      "Epoch 14/15\n",
      "2870/2870 [==============================] - 608s 212ms/step - loss: 1.1831 - acc: 0.5539\n",
      "\n",
      "Epoch 00014: acc improved from 0.54811 to 0.55396, saving model to /data/inception\n",
      "Epoch 15/15\n",
      "2870/2870 [==============================] - 609s 212ms/step - loss: 1.1747 - acc: 0.5583\n",
      "\n",
      "Epoch 00015: acc improved from 0.55396 to 0.55832, saving model to /data/inception\n"
     ]
    }
   ],
   "source": [
    "continue_finetune(train_dir = train_data_dir, nb_epoch= 15, batch_size=BAT_SIZE, out_dir = \"/data/inception\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(out_dir, monitor='acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "\n",
    "history_tl = new_model.fit_generator(\n",
    "train_generator,\n",
    "nb_epoch=nb_epoch,\n",
    "samples_per_epoch=nb_train_samples,\n",
    "#     validation_data=validation_generator,\n",
    "#     nb_val_samples=nb_val_samples,\n",
    "class_weight='auto',\n",
    "callbacks = [checkpoint, early])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "    \n",
    "    — train_dir flower_photos/train \\\n",
    " — val_dir flower_photos/validation \\ \n",
    " — nb_epoch 50 \\ \n",
    " — batch_size 10 \\ \n",
    " — output_model_file inception_yo1.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from PIL import Image,ImageDraw,ImageFont\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(model, img, target_size):\n",
    "    \"\"\"Run model prediction on image\n",
    "    Args:\n",
    "    model: keras model\n",
    "    img: PIL format image\n",
    "    target_size: (w,h) tuple\n",
    "    Returns:\n",
    "    list of predicted labels and their probabilities\n",
    "    \"\"\"\n",
    "    if img.size != target_size:\n",
    "    img = img.resize(target_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    preds = model.predict(x)\n",
    "    return preds[0]\n",
    "\n",
    "if __name__==\"__main__\":\n",
    " a = argparse.ArgumentParser()\n",
    " a.add_argument(\" - image\", help=\"path to image\")\n",
    " a.add_argument(\" - image_url\", help=\"url to image\")\n",
    " a.add_argument(\" - model\")\n",
    " args = a.parse_args()\n",
    " \n",
    " if args.image is None and args.image_url is None:\n",
    " a.print_help()\n",
    " sys.exit(1)\n",
    "model = load_model(args.model)\n",
    " model.fit()\n",
    " if args.image is not None:\n",
    " labels = (\"daisy\", \"dandelion\",\"roses\",\"sunflower\",\"tulips\")\n",
    " image1 = Image.open(args.image)\n",
    " preds = predict(model, image1, target_size) \n",
    " print(preds)\n",
    " preds = preds.tolist()\n",
    " plot_preds(image1, preds)\n",
    " fonttype = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\",18)\n",
    " draw = ImageDraw.Draw(image1)\n",
    " draw.text(xy=(5,5),text = str(labels[preds.index(max(preds))])+\":\"+str(max(preds)),fill = (255,255,255,128),font = fonttype)\n",
    " image1.show()\n",
    " image1.save((args.image).split(\".\")[0]+\"1\"+\".jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
