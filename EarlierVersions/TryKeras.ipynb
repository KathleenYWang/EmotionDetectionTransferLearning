{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/applications/#inceptionv3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### include_top\n",
    "For ImageNet dataset, there are different 1000 labels to categorize the images. Thus, when you want to train a model with ImageNet dataset, you need to specify the number of neurons in the output (softmax) layer as 1000. However, we have such a dataset with ~50 -actually, 46- labels to categorize the images. We should not include the top (output, softmax, last, whatever you would like to call) layer of ResNet50 for our model, so we can add a new layer and specify the number of neurons as what the dataset needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/transfer-learning-for-image-classification-using-keras-c47ccf09c8c8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_width, img_height = 256, 256\n",
    "input_shape = (1, img_width, img_height)\n",
    "train_data_dir = \"/root/finalproject/tensorflow-for-poets-2/tf_files/Training\"\n",
    "# validation_data_dir = \"data/val\"\n",
    "# nb_train_samples = 4125\n",
    "# nb_validation_samples = 466 \n",
    " \n",
    "batch_size = 16\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "base_model = applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_tensor=None, input_shape = None, pooling=None)\n",
    "# create the base pre-trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/https-medium-com-manishchablani-useful-keras-features-4bac0724734c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pooling: Optional pooling mode for feature extraction when include_top is False.  \n",
    "None means that the output of the model will be the 4D tensor output of the last convolutional layer.  \n",
    "'avg' means that global average pooling will be applied to the output of the last convolutional layer, and thus the output of the model will be a 2D tensor.  \n",
    "'max' means that global max pooling will be applied.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- for this example we have 7 classes\n",
    "predictions = Dense(7, activation='softmax')(x)\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.3,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28707 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size, \n",
    "class_mode = \"categorical\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1795"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_size = 28707 \n",
    "steps_per_epoch = len(train_generator)\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"inception_v3\", monitor='acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='acc', min_delta=0, patience=10, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1795/1795 [==============================] - 950s 529ms/step - loss: 1.7152 - acc: 0.3039\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.30376, saving model to inception_v3\n",
      "Epoch 2/100\n",
      "1795/1795 [==============================] - 950s 529ms/step - loss: 1.7091 - acc: 0.3057\n",
      "\n",
      "Epoch 00002: acc improved from 0.30376 to 0.30567, saving model to inception_v3\n",
      "Epoch 3/100\n",
      "1795/1795 [==============================] - 949s 529ms/step - loss: 1.7059 - acc: 0.3101\n",
      "\n",
      "Epoch 00003: acc improved from 0.30567 to 0.31020, saving model to inception_v3\n",
      "Epoch 4/100\n",
      "1795/1795 [==============================] - 948s 528ms/step - loss: 1.7053 - acc: 0.3151\n",
      "\n",
      "Epoch 00004: acc improved from 0.31020 to 0.31480, saving model to inception_v3\n",
      "Epoch 5/100\n",
      "1795/1795 [==============================] - 951s 530ms/step - loss: 1.6946 - acc: 0.3209\n",
      "\n",
      "Epoch 00005: acc improved from 0.31480 to 0.32107, saving model to inception_v3\n",
      "Epoch 6/100\n",
      "1795/1795 [==============================] - 953s 531ms/step - loss: 1.6950 - acc: 0.3195\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.32107\n",
      "Epoch 7/100\n",
      "1795/1795 [==============================] - 953s 531ms/step - loss: 1.6931 - acc: 0.3167\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.32107\n",
      "Epoch 8/100\n",
      "1795/1795 [==============================] - 952s 530ms/step - loss: 1.7003 - acc: 0.3206\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.32107\n",
      "Epoch 9/100\n",
      "1795/1795 [==============================] - 955s 532ms/step - loss: 1.6873 - acc: 0.3205\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.32107\n",
      "Epoch 10/100\n",
      "1795/1795 [==============================] - 959s 534ms/step - loss: 1.6898 - acc: 0.3228\n",
      "\n",
      "Epoch 00010: acc improved from 0.32107 to 0.32295, saving model to inception_v3\n",
      "Epoch 11/100\n",
      "1795/1795 [==============================] - 956s 533ms/step - loss: 1.6954 - acc: 0.3220\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.32295\n",
      "Epoch 12/100\n",
      "1795/1795 [==============================] - 957s 533ms/step - loss: 1.6839 - acc: 0.3259\n",
      "\n",
      "Epoch 00012: acc improved from 0.32295 to 0.32591, saving model to inception_v3\n",
      "Epoch 13/100\n",
      "1795/1795 [==============================] - 956s 533ms/step - loss: 1.6887 - acc: 0.3247\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.32591\n",
      "Epoch 14/100\n",
      "1795/1795 [==============================] - 953s 531ms/step - loss: 1.6957 - acc: 0.3194\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.32591\n",
      "Epoch 15/100\n",
      "1795/1795 [==============================] - 952s 531ms/step - loss: 1.6919 - acc: 0.3220\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.32591\n",
      "Epoch 16/100\n",
      "1795/1795 [==============================] - 960s 535ms/step - loss: 1.6890 - acc: 0.3194\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.32591\n",
      "Epoch 17/100\n",
      "1795/1795 [==============================] - 965s 538ms/step - loss: 1.6851 - acc: 0.3287\n",
      "\n",
      "Epoch 00017: acc improved from 0.32591 to 0.32867, saving model to inception_v3\n",
      "Epoch 18/100\n",
      "1795/1795 [==============================] - 957s 533ms/step - loss: 1.6934 - acc: 0.3258\n",
      "\n",
      "Epoch 00018: acc did not improve from 0.32867\n",
      "Epoch 19/100\n",
      "1795/1795 [==============================] - 956s 533ms/step - loss: 1.6831 - acc: 0.3249\n",
      "\n",
      "Epoch 00019: acc did not improve from 0.32867\n",
      "Epoch 20/100\n",
      "1795/1795 [==============================] - 957s 533ms/step - loss: 1.6879 - acc: 0.3284\n",
      "\n",
      "Epoch 00020: acc did not improve from 0.32867\n",
      "Epoch 21/100\n",
      "1795/1795 [==============================] - 958s 533ms/step - loss: 1.6934 - acc: 0.3249\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.32867\n",
      "Epoch 22/100\n",
      "1795/1795 [==============================] - 963s 537ms/step - loss: 1.6818 - acc: 0.3305\n",
      "\n",
      "Epoch 00022: acc improved from 0.32867 to 0.33055, saving model to inception_v3\n",
      "Epoch 23/100\n",
      "1795/1795 [==============================] - 955s 532ms/step - loss: 1.6910 - acc: 0.3255\n",
      "\n",
      "Epoch 00023: acc did not improve from 0.33055\n",
      "Epoch 24/100\n",
      "1795/1795 [==============================] - 956s 532ms/step - loss: 1.6815 - acc: 0.3302\n",
      "\n",
      "Epoch 00024: acc did not improve from 0.33055\n",
      "Epoch 25/100\n",
      "1795/1795 [==============================] - 951s 530ms/step - loss: 1.6896 - acc: 0.3281\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.33055\n",
      "Epoch 26/100\n",
      "1795/1795 [==============================] - 952s 531ms/step - loss: 1.6869 - acc: 0.3291\n",
      "\n",
      "Epoch 00026: acc did not improve from 0.33055\n",
      "Epoch 27/100\n",
      "1795/1795 [==============================] - 951s 530ms/step - loss: 1.6915 - acc: 0.3258\n",
      "\n",
      "Epoch 00027: acc did not improve from 0.33055\n",
      "Epoch 28/100\n",
      "1795/1795 [==============================] - 951s 530ms/step - loss: 1.6880 - acc: 0.3274\n",
      "\n",
      "Epoch 00028: acc did not improve from 0.33055\n",
      "Epoch 29/100\n",
      "1795/1795 [==============================] - 958s 534ms/step - loss: 1.6826 - acc: 0.3261\n",
      "\n",
      "Epoch 00029: acc did not improve from 0.33055\n",
      "Epoch 30/100\n",
      "1795/1795 [==============================] - 956s 533ms/step - loss: 1.6927 - acc: 0.3229\n",
      "\n",
      "Epoch 00030: acc did not improve from 0.33055\n",
      "Epoch 31/100\n",
      "1795/1795 [==============================] - 956s 533ms/step - loss: 1.6879 - acc: 0.3286\n",
      "\n",
      "Epoch 00031: acc did not improve from 0.33055\n",
      "Epoch 32/100\n",
      "1795/1795 [==============================] - 953s 531ms/step - loss: 1.6848 - acc: 0.3290\n",
      "\n",
      "Epoch 00032: acc did not improve from 0.33055\n",
      "Epoch 00032: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e32b25fd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the model \n",
    "model.fit_generator(\n",
    "train_generator,\n",
    "# samples_per_epoch = nb_train_samples,\n",
    "epochs = epochs,\n",
    "steps_per_epoch = steps_per_epoch,\n",
    "# validation_data = validation_generator,\n",
    "# nb_val_samples = nb_validation_samples,\n",
    "callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(16, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "# Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.3,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=30)\n",
    "\n",
    "# test_datagen = ImageDataGenerator(\n",
    "# rescale = 1./255,\n",
    "# horizontal_flip = True,\n",
    "# fill_mode = \"nearest\",\n",
    "# zoom_range = 0.3,\n",
    "# width_shift_range = 0.3,\n",
    "# height_shift_range=0.3,\n",
    "# rotation_range=30)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size, \n",
    "class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "validation_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "class_mode = \"categorical\")\n",
    "\n",
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "# Train the model \n",
    "model_final.fit_generator(\n",
    "train_generator,\n",
    "samples_per_epoch = nb_train_samples,\n",
    "epochs = epochs,\n",
    "validation_data = validation_generator,\n",
    "nb_val_samples = nb_validation_samples,\n",
    "callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_to_visualize(layer):\n",
    "    inputs = [K.learning_phase()] + model.inputs\n",
    "\n",
    "    _convout1_f = K.function(inputs, [layer.output])\n",
    "    def convout1_f(X):\n",
    "        # The [0] is to disable the training phase flag\n",
    "        return _convout1_f([0] + [X])\n",
    "\n",
    "    convolutions = convout1_f(img_to_visualize)\n",
    "    convolutions = np.squeeze(convolutions)\n",
    "\n",
    "    print ('Shape of conv:', convolutions.shape)\n",
    "\n",
    "    n = convolutions.shape[0]\n",
    "    n = int(np.ceil(np.sqrt(n)))\n",
    "\n",
    "    # Visualization of each filter of the layer\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    for i in range(len(convolutions)):\n",
    "        ax = fig.add_subplot(n,n,i+1)\n",
    "        ax.imshow(convolutions[i], cmap='gray')\n",
    "\n",
    "# Specify the layer to want to visualize\n",
    "layer_to_visualize(convout1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
